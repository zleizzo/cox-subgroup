{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process NASA Turbofan Data for Survival Analysis\n",
    "\n",
    "This notebook processes the NASA turbofan jet engine dataset into a format compatible with the survival analysis utilities in this repo.\n",
    "\n",
    "## Data Description\n",
    "- Multiple engines, each with time series of sensor measurements until failure\n",
    "- 3 operational settings (discrete operating conditions with sensor noise)\n",
    "- 21 sensor measurements\n",
    "- Goal: Predict Remaining Useful Life (RUL)\n",
    "\n",
    "## Transformation Strategy\n",
    "Each time series measurement becomes a separate datapoint:\n",
    "- **time**: RUL = cycles until failure from current measurement\n",
    "- **failure**: True (all engines run to failure in training data)\n",
    "- Features: operational settings + sensor measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names based on readme.txt and Table 2 in the PDF documentation\n",
    "# Using interpretable names from C-MAPSS simulation\n",
    "column_names = ['unit_id', 'cycle'] + \\\n",
    "               ['op_setting_1', 'op_setting_2', 'op_setting_3'] + \\\n",
    "               ['T2', 'T24', 'T30', 'T50', 'P2', 'P15', 'P30',\n",
    "                'Nf', 'Nc', 'epr', 'Ps30', 'phi', 'NRf', 'NRc',\n",
    "                'BPR', 'farB', 'htBleed', 'Nf_dmd', 'PCNfR_dmd', 'W31', 'W32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_turbofan_file(filepath):\n",
    "    \"\"\"Load a single turbofan data file.\"\"\"\n",
    "    df = pd.read_csv(filepath, sep='\\s+', header=None, names=column_names)\n",
    "    return df\n",
    "\n",
    "def compute_rul(df):\n",
    "    \"\"\"\n",
    "    Compute Remaining Useful Life (RUL) for each measurement.\n",
    "    RUL = max_cycle - current_cycle\n",
    "    \"\"\"\n",
    "    # Get max cycle for each engine (time of failure)\n",
    "    max_cycles = df.groupby('unit_id')['cycle'].max()\n",
    "    \n",
    "    # Compute RUL for each row\n",
    "    df['time'] = df.apply(lambda row: max_cycles[row['unit_id']] - row['cycle'], axis=1)\n",
    "    \n",
    "    # All training data has observed failures\n",
    "    df['failure'] = True\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Each Dataset\n",
    "\n",
    "There are 4 datasets:\n",
    "- **FD001**: 1 operating condition, 1 fault mode\n",
    "- **FD002**: 6 operating conditions, 1 fault mode\n",
    "- **FD003**: 1 operating condition, 2 fault modes\n",
    "- **FD004**: 6 operating conditions, 2 fault modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing FD001...\n",
      "\n",
      "Processing FD002...\n",
      "\n",
      "Processing FD003...\n",
      "\n",
      "Processing FD004...\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path('../data/raw/nasa')\n",
    "datasets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"\\nProcessing {dataset}...\")\n",
    "    \n",
    "    train_file = data_dir / f'train_{dataset}.txt'\n",
    "    df_train = load_turbofan_file(train_file)\n",
    "    \n",
    "    df_train = compute_rul(df_train)\n",
    "    \n",
    "    all_data[dataset] = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved combined dataset: processed/nasa_turbofan_combined_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "# Add dataset identifier to each dataframe\n",
    "for dataset, df in all_data.items():\n",
    "    df['dataset'] = dataset\n",
    "\n",
    "df_combined = pd.concat(all_data.values(), ignore_index=True)\n",
    "output_file = 'processed/nasa_turbofan_combined_processed.pkl'\n",
    "df_combined.to_pickle(output_file)\n",
    "print(f\"\\nSaved combined dataset: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
