# README.md

This is the repo for the paper "Subgroup Discovery with the Cox Model." This readme file was generated by Claude Code and checked by the authors. It provides a concise overview to the repo. More details for reproducing the results can be found in each of the individual notebooks found in the `notebooks` directory.

## Overview

Research codebase for survival analysis subgroup discovery methods. Compares algorithms (DDGroup, Cox trees, PRIM, survival trees, random baseline) for identifying subgroups in survival data. Experiments run locally or on SLURM clusters.

## Environment Setup

```bash
conda env create -f environment.yml
conda activate survival
```

Key dependencies: scikit-survival, scikit-learn, pandas, numpy, joblib, PyTorch

## Running Experiments

### Local
```bash
cd experiments
python run_local.py <config_name>              # Run all jobs
python run_local.py <config_name> 0 10         # Run jobs 0-9
```

### SLURM
```bash
cd experiments
# Generate scripts via make_job_scripts.ipynb first
sbatch {config}_0.sh
```

### Analysis Pipeline
```bash
cd analysis
python process_results.py <config_name>                                    # Step 1: Process raw results
python gen_combined_tables.py <cfg1> <cfg2> --size_threshold 0.05          # Step 2: Generate tables
```

## Architecture

### Core Components

**src/algs/** - Subgroup discovery algorithms
- Each implements `*_job(X_adjust, X_subgp, Y, B_subgp, **kwargs)` returning list of `{subgroup_id, R, beta, ...}`
- Methods registered in `METHOD_DICT` in [src/config/constants.py](src/config/constants.py)

**src/data/** - Data loading
- [load.py](src/data/load.py): `load_data()` returns `X_adjust, X_subgp, Y, X_adjust_test, X_subgp_test, Y_test, B_subgp, scaler`
- Y is structured array with `failure` (bool) and `time` (float) fields, **always sorted by time**

**src/utils/** - Utilities
- [subgroup.py](src/utils/subgroup.py): Cox model fitting, region checking, rejection scores
- [metrics.py](src/utils/metrics.py): EPE, c-index, partial log-likelihood, box IoU/F1

**src/evaluation/** - Experiment runner
- [run_experiment.py](src/evaluation/run_experiment.py): Loads data, runs method, evaluates, saves to `results/{config}/raw/{task_id}_results.pkl`

**src/config/** - Configuration
- [constants.py](src/config/constants.py): `METHOD_DICT`, `METHOD_HYPERS`, dataset column names

### Experiment Configs

YAML files in `experiments/configs/` define:
- `datasets`: dataset name → `{subgp_cols, adjust_cols, seeds, hypers, R_star (optional)}`
- `methods`: list of method names

Note: `subgp_cols` and `adjust_cols` are column indices in the original feature space.

## Key Conventions

- **Path handling**: Scripts run from their directory (`cd experiments` or `cd analysis`), use `sys.path.append("../src")`
- **Regions (R)**: 2×d numpy arrays, `R[0,:]` = lower bounds, `R[1,:]` = upper bounds
- **Bounding box (B)**: Maximum allowed region, same format as R
- **Results**: `{task_id}_results.pkl` (DataFrame with metrics), `{task_id}_runtime.pkl` (timing)

## Datasets

- **Real**: METABRIC, NASA turbofan (from processed pickles), sksurv datasets (veterans_lung_cancer, gbsg2, aids, whas500)
- **Synthetic**: `nonlinear` (generated on-the-fly with specified n)
- **Data format**: X = numpy array, Y = structured array `[('failure', '?'), ('time', '<f8')]`

## Notebooks

Key analysis notebooks in `notebooks/`:
- `Table 2 - Nonlinear Synthetic.ipynb`: Synthetic data experiments
- `Table 3 - Real Data.ipynb`: Real dataset experiments
- `Table 4 - NASA Case Study.ipynb`: NASA turbofan case study
- `Fig. 1 + Table 1 - Need for CRS.ipynb`: Motivation figures
